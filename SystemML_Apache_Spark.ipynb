{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#!pip install --upgrade systemml\n! pip install --upgrade https://github.com/niketanpansare/future_of_data/raw/master/systemml-1.0.0-SNAPSHOT-python.tar.gz",
            "execution_count": 10,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting https://github.com/niketanpansare/future_of_data/raw/master/systemml-1.0.0-SNAPSHOT-python.tar.gz\n\u001b[?25l  Downloading https://github.com/niketanpansare/future_of_data/raw/master/systemml-1.0.0-SNAPSHOT-python.tar.gz (10.3MB)\n\u001b[K    100% |################################| 10.3MB 2.1MB/s eta 0:00:01\n\u001b[?25hCollecting numpy>=1.8.2 (from systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl\nCollecting scipy>=0.15.1 (from systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/dc/29/162476fd44203116e7980cfbd9352eef9db37c49445d1fec35509022f6aa/scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl\nCollecting pandas (from systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/8e/86/c14387d6813ebadb7bf61b9ad270ffff111c8b587e4d266e07de774e385e/pandas-1.0.4-cp36-cp36m-manylinux1_x86_64.whl\nCollecting scikit-learn (from systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl\nCollecting Pillow>=2.0.0 (from systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/e0/50/8e78e6f62ffa50d6ca95c281d5a2819bef66d023ac1b723e253de5bda9c5/Pillow-7.1.2-cp36-cp36m-manylinux1_x86_64.whl\nCollecting pytz>=2017.2 (from pandas->systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl\nCollecting python-dateutil>=2.6.1 (from pandas->systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl\nCollecting joblib>=0.11 (from scikit-learn->systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl\nCollecting threadpoolctl>=2.0.0 (from scikit-learn->systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\nCollecting six>=1.5 (from python-dateutil>=2.6.1->pandas->systemml==1.0.0)\n  Using cached https://files.pythonhosted.org/packages/ee/ff/48bde5c0f013094d729fe4b0316ba2a24774b3ff1c52d924a8a4cb04078a/six-1.15.0-py2.py3-none-any.whl\nBuilding wheels for collected packages: systemml\n  Building wheel for systemml (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/54/eb/1e/7e6d0275e0a927cd02b17353f02ce2596ded44cfc100100b9a\nSuccessfully built systemml\n\u001b[31mtensorflow 1.13.1 requires tensorboard<1.14.0,>=1.13.0, which is not installed.\u001b[0m\n\u001b[31mpytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\u001b[0m\n\u001b[31mpytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n\u001b[31mpytest-openfiles 0.5.0 has requirement pytest>=4.6, but you'll have pytest 3.10.1 which is incompatible.\u001b[0m\n\u001b[31mpytest-astropy 0.8.0 has requirement pytest>=4.6, but you'll have pytest 3.10.1 which is incompatible.\u001b[0m\nInstalling collected packages: numpy, scipy, pytz, six, python-dateutil, pandas, joblib, threadpoolctl, scikit-learn, Pillow, systemml\nSuccessfully installed Pillow-7.1.2 joblib-0.15.1 numpy-1.18.4 pandas-1.0.4 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.23.1 scipy-1.4.1 six-1.15.0 systemml-1.0.0 threadpoolctl-2.1.0\n\u001b[31mException:\nTraceback (most recent call last):\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/cli/base_command.py\", line 176, in main\n    status = self.run(options, args)\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 441, in run\n    options.target_dir, target_temp_dir, options.upgrade\n  File \"/opt/ibm/conda/miniconda3.6/lib/python3.6/site-packages/pip/_internal/commands/install.py\", line 492, in _handle_target_dir\n    shutil.rmtree(target_item_dir)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 486, in rmtree\n    _rmtree_safe_fd(fd, path, onerror)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 424, in _rmtree_safe_fd\n    _rmtree_safe_fd(dirfd, fullname, onerror)\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 428, in _rmtree_safe_fd\n    onerror(os.rmdir, fullname, sys.exc_info())\n  File \"/home/spark/conda/envs/python3.6/lib/python3.6/shutil.py\", line 426, in _rmtree_safe_fd\n    os.rmdir(name, dir_fd=topfd)\nOSError: [Errno 39] Directory not empty: 'csgraph'\u001b[0m\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!ln -s -f ~/.local/lib/python3.6/site-packages/systemml/systemml-java/*.java ~/data/libs",
            "execution_count": 8,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "ln: failed to create symbolic link '/home/spark/shared/data/libs': No such file or directory\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!pip show systemml",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Name: systemml\r\nVersion: 1.2.0\r\nSummary: Apache SystemML is a distributed and declarative machine learning platform.\r\nHome-page: http://systemml.apache.org/\r\nAuthor: Apache SystemML\r\nAuthor-email: dev@systemml.apache.org\r\nLicense: Apache 2.0\r\nLocation: /home/spark/shared/user-libs/python3.6\r\nRequires: scikit-learn, numpy, pandas, Pillow, scipy\r\nRequired-by: \r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sc.version",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "'2.3.4'"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from systemml import MLContext, dml",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ml = MLContext(sc)\nprint(ml.info())",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Archiver-Version: Plexus Archiver\nArtifact-Id: systemml\nBuild-Jdk: 1.8.0_121\nBuild-Time: 2017-04-19 21:45:10 UTC\nBuilt-By: asurve\nCreated-By: Apache Maven 3.3.9\nGroup-Id: org.apache.systemml\nMain-Class: org.apache.sysml.api.DMLScript\nManifest-Version: 1.0\nMinimum-Recommended-Spark-Version: 2.1.0\nVersion: 0.14.0-incubating\n\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "script = dml(\"\"\"\nprint('Hello World');\n\"\"\")\nml.execute(script)",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "'JavaPackage' object is not callable",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-11-116474a81d1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hello World'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\")\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m/home/spark/shared/user-libs/python3.6/systemml/mlcontext.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, script)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mdefault_jvm_stdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_jvm_stdout_parallel_flush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault_jvm_stdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mjvm_stdout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_flush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_jvm_stdout_parallel_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMLResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_java\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m/home/spark/shared/user-libs/python3.6/systemml/classloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parallel_flush)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_flush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_spark_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msysml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_flush\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparallel_flush\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_stdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mTypeError\u001b[0m: 'JavaPackage' object is not callable"
                    ]
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python36",
            "display_name": "Python 3.6 with Spark",
            "language": "python3"
        },
        "language_info": {
            "mimetype": "text/x-python",
            "nbconvert_exporter": "python",
            "name": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8",
            "file_extension": ".py",
            "codemirror_mode": {
                "version": 3,
                "name": "ipython"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}